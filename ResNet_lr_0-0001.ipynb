{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNet_new_0_0001_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This notebook tunes a ResNet CNN to images of chest x-rays. \n",
        "The code is set up to run in GoogleColab in order to utilise GPU. \n",
        "The input data is loaded from GDrive. \n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HCealDPCnfQV",
        "outputId": "88cf33fc-e72e-4de4-ec96-f4727bf430ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThis notebook tunes a ResNet CNN to images of chest x-rays. \\nThe code is set up to run in GoogleColab in order to utilise GPU. \\nThe input data is loaded from GDrive. \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b192qJWt6xb7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from google.colab import drive, files\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from keras.models import Sequential\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import keras\n",
        "import pickle\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check access to a GPU & print specs\n",
        "def check_gpu():\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "  else:\n",
        "    print(gpu_info)"
      ],
      "metadata": {
        "id": "5VNl9XE3oJZr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mount_to_Gdrive(path='/content/gdrive'):\n",
        "  drive.mount(path)"
      ],
      "metadata": {
        "id": "CQn0yOFPoo6a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_files():\n",
        "  #Copy files folder\n",
        "  %cp -av 'gdrive/MyDrive/files' '/content'\n",
        "\n",
        "  # Move files from GDrive\n",
        "  if 'Train' not in os.listdir():\n",
        "    os.makedirs('Train')\n",
        "  if 'Test' not in os.listdir():\n",
        "    os.makedirs('Test')\n",
        "\n",
        "  shutil.move('files/train_resize.zip', 'Train/')   \n",
        "  shutil.move('files/test_resize.zip', 'Test/')   "
      ],
      "metadata": {
        "id": "gJDS1P_GteJ1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_files():\n",
        "  # Unzip train files\n",
        "  with zipfile.ZipFile('Train/train_resize.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('Train/')\n",
        "  # Unzip test files\n",
        "  with zipfile.ZipFile('Test/test_resize.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('Test/')"
      ],
      "metadata": {
        "id": "o2K7ho9MtZxu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def undersample_data(df):\n",
        "  # Get list of classes in training set \n",
        "  train_list=pd.read_csv('files/train_val_list.txt', header=None)[0].tolist()\n",
        "  # Get list of 'No Finding' class which is majority \n",
        "  nf_index=df[(df['Finding Labels']=='No Finding') & (df['Image Index'].isin(train_list))].index\n",
        "  # Randomly drop a subset of these \n",
        "  nf_index_drop=np.random.choice(nf_index, 40000, replace=False)\n",
        "  nf_images_drop=df[df.index.isin(nf_index_drop)]['Image Index'].tolist()\n",
        "  # Remove images designated to be dropped from folder directory \n",
        "  for i in nf_images_drop:\n",
        "    os.remove('Train/train_resize/'+str(i))\n",
        "  # Remove images designated to be droppped from tabular data \n",
        "  df=df[~df.index.isin(nf_index_drop)]\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  print(len(df))\n",
        "  return df"
      ],
      "metadata": {
        "id": "03G5orB8utXZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(train_path, test_path):\n",
        "  df=pd.read_csv(r'files/Data_Entry_2017_v2020.csv')\n",
        "  # Get Labels of train val images as they will be read in order \n",
        "  labels=pd.DataFrame([*os.walk(train_path)][0][2])\n",
        "  labels.columns=['Image']\n",
        "\n",
        "  # #Merge labels with the df file. \n",
        "  labels=labels.merge(df[['Image Index', 'Finding Labels']], left_on='Image', right_on='Image Index')\n",
        "  labels.drop('Image Index', axis=1, inplace=True)\n",
        "  #One Hot Encode Labels \n",
        "  labels=pd.concat([labels, labels['Finding Labels'].str.get_dummies(sep=\"|\")], axis=1)\n",
        "  labels['Path']=labels['Image'].apply(lambda x: train_path+str(x) )\n",
        "\n",
        "  # Test Set\n",
        "  test=pd.DataFrame([*os.walk(test_path)][0][2])\n",
        "  test.columns=['Image']\n",
        "\n",
        "  # Merge labels with the df file.\n",
        "  test=test.merge(df[['Image Index', 'Finding Labels']], left_on='Image', right_on='Image Index')\n",
        "  test.drop('Image Index', axis=1, inplace=True)\n",
        "  #One Hot Encode\n",
        "  test=pd.concat([test, test['Finding Labels'].str.get_dummies(sep=\"|\")], axis=1)\n",
        "  test['Path']=test['Image'].apply(lambda x: train_path+str(x) )\n",
        "\n",
        "  return labels, test, df"
      ],
      "metadata": {
        "id": "JWLfKBNJ0F48"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_class_weights(labels):\n",
        "  # Separate the labels df into those where there are more than 1 entry, and those where there is a single entry \n",
        "  labels_ = labels[labels['Finding Labels'].apply(lambda x: x.count(\"|\"))==0]\n",
        "  labels__= labels[labels['Finding Labels'].apply(lambda x: x.count(\"|\"))!=0]\n",
        "\n",
        "  # Encode class labels \n",
        "  ord_enc = OrdinalEncoder()\n",
        "  labels_[\"Encoded\"] = ord_enc.fit_transform(labels_[[\"Finding Labels\"]])\n",
        "  print(labels_['Encoded'].nunique())\n",
        "  labels__['Encoded']=16\n",
        "\n",
        "  labels=pd.concat([labels_, labels__])\n",
        "\n",
        "  # Compute Class weights based on distribution of classes \n",
        "  class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels['Encoded']), y=labels['Encoded'])\n",
        "  vals=class_weights[:-1]\n",
        "  # Store in dictionary \n",
        "  class_weights_dict=dict(enumerate(vals))\n",
        "\n",
        "  # Create df to summarise number of observations & weight per class \n",
        "  classes=pd.merge(labels['Encoded'].value_counts(), pd.DataFrame(data=class_weights_dict.items()).iloc[:, -1], left_index=True, right_index=True)\n",
        "  classes.columns=['Observations', 'Class weight']\n",
        "\n",
        "  print(classes)\n",
        "  \n",
        "  return labels, class_weights_dict"
      ],
      "metadata": {
        "id": "KMJy2uhV0F8m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_generators(labels, train_path, test_path):\n",
        "  # Create generators per training, val & test datasets\n",
        "  datagen=ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
        "  val_datagen=ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
        "  test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Define generators per set. Set batch size to 64 \n",
        "  train_generator=datagen.flow_from_dataframe(dataframe=labels.loc[:, :], x_col='Image', y_col=labels.columns[2:-2], directory=train_path, class_mode='raw', batch_size=64, target_size=(224, 224), subset='training')\n",
        "  val_generator=val_datagen.flow_from_dataframe(dataframe=labels.loc[:, :], x_col='Image', y_col=labels.columns[2:-2], directory=train_path, class_mode='raw', batch_size=64, target_size=(224, 224), subset='validation')\n",
        "  test_generator=test_datagen.flow_from_dataframe(dataframe=test, x_col='Image', y_col=test.columns[2:-2], directory=test_path, class_mode='raw', batch_size=64, target_size=(224, 224), shuffle=False)\n",
        "  return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "SJKDuUte05cG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trainable=False):\n",
        "  # Download pretrained resnet for feature reduction (no classification layer)\n",
        "  resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling=None )\n",
        "  resnet.trainable = trainable\n",
        "\n",
        "  # Append layers for training classification\n",
        "  model = tf.keras.Sequential([\n",
        "    resnet,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(50),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(30),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(15),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('sigmoid')])\n",
        "  return model "
      ],
      "metadata": {
        "id": "Vsk0Kxdu81IB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_generator, val_generator, test_generator, model, my_callbacks ):\n",
        "  res=pd.DataFrame() # Create df to store results \n",
        "  count=1\n",
        "  for lr in [0.0001]: # a range of learning rates were tested , including [0.001, 0.0001, 0.00001] with training done in seperate notebooks to speed up tuning \n",
        "    for optimizer in [tf.keras.optimizers.Adam(learning_rate=lr), tf.keras.optimizers.SGD(learning_rate=lr)]:\n",
        "      for batch in [32, 256, 512]:\n",
        "        print(lr, optimizer, batch)\n",
        "\n",
        "        key=str(lr)+\"_\"+str(count)+\"_\"+str(batch)\n",
        "\n",
        "        # Estimate step size for generator \n",
        "        STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "\n",
        "        # Compile Model with metrics = Accuracy & AUC\n",
        "        model.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[tf.keras.metrics.binary_accuracy, tf.keras.metrics.AUC(multi_label=True)])\n",
        "\n",
        "        # Fit Model \n",
        "        history = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_generator, class_weight=class_weights_dict, #callbacks=my_callbacks,\n",
        "                            epochs=50)\n",
        "        # Predict \n",
        "        preds=model.predict(test_generator)\n",
        "\n",
        "        # Store ROC_AUC scores for each class \n",
        "        for i in range(15):\n",
        "          res.loc[i, 'Disease'+str(key)]= test.columns[i+2]\n",
        "          res.loc[i, 'AUC'+str(key)] = roc_auc_score(test.iloc[:,i+2], preds[:,i], average='samples')\n",
        "        # Store in Colab folder \n",
        "        with open('/ResNetDict_0_0001', 'ab') as file_pi:\n",
        "            pickle.dump(history.history, file_pi)\n",
        "\n",
        "        count=count+1\n",
        " "
      ],
      "metadata": {
        "id": "7ThiTUya-Xsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check access to GPU within COlab & print specs \n",
        "check_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yx5GXiwoFoK",
        "outputId": "fe04f88e-7885-4779-a336-d64eac8dfaf7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  6 21:23:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to GDrive where data is stored \n",
        "mount_to_Gdrive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8TBKjtohxo",
        "outputId": "ec8ad6b9-d25e-474b-a685-ea5b5d73c556"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy files within Gdrive to relevant folders\n",
        "copy_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC-HneHYtPNh",
        "outputId": "969a842e-ac1e-46fc-8b37-80c0409d4d0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'gdrive/MyDrive/files' -> '/content/files'\n",
            "'gdrive/MyDrive/files/train_val_list.txt' -> '/content/files/train_val_list.txt'\n",
            "'gdrive/MyDrive/files/test_list.txt' -> '/content/files/test_list.txt'\n",
            "'gdrive/MyDrive/files/Data_Entry_2017_v2020.csv' -> '/content/files/Data_Entry_2017_v2020.csv'\n",
            "'gdrive/MyDrive/files/test_resize.zip' -> '/content/files/test_resize.zip'\n",
            "'gdrive/MyDrive/files/train_resize.zip' -> '/content/files/train_resize.zip'\n",
            "'gdrive/MyDrive/files/ResNetDict_0_00001' -> '/content/files/ResNetDict_0_00001'\n",
            "'gdrive/MyDrive/files/res_ResNet_0_00001.csv' -> '/content/files/res_ResNet_0_00001.csv'\n",
            "'gdrive/MyDrive/files/res_ResNet_0_001.csv' -> '/content/files/res_ResNet_0_001.csv'\n",
            "'gdrive/MyDrive/files/ResNetDict_0_001' -> '/content/files/ResNetDict_0_001'\n",
            "'gdrive/MyDrive/files/res_ResNet_0_0001.csv' -> '/content/files/res_ResNet_0_0001.csv'\n",
            "'gdrive/MyDrive/files/ResNetDict_0_0001' -> '/content/files/ResNetDict_0_0001'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip folders of images \n",
        "unzip_files()"
      ],
      "metadata": {
        "id": "Y9t-rSnQtRKJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf2DSaJHCSAf"
      },
      "source": [
        "# Import tabular data\n",
        "df=pd.read_csv(r'files/Data_Entry_2017_v2020.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersample majority class 'No Finding' (class weights to be applied during training too)\n",
        "undersample=True\n",
        "if undersample==True:\n",
        "  df=undersample_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wavlQ6Nmt-9a",
        "outputId": "4f8c09a2-1352-48be-bd29-d82d60629b57"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHo-cart7dwp"
      },
      "source": [
        "train_path='Train/train_resize'\n",
        "test_path='Test/test_resize'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, test, df=process_data(train_path=train_path, test_path=test_path)"
      ],
      "metadata": {
        "id": "LWanehq4yLKE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, class_weights_dict=compute_class_weights(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_38i99blymrc",
        "outputId": "3f241eed-5f67-4127-b46b-d5dd33e4d5f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "      Observations  Class weight\n",
            "10.0         10500      0.276929\n",
            "8.0           7327      0.396854\n",
            "0.0           3414      0.851714\n",
            "4.0           2788      1.042952\n",
            "11.0          2248      1.293483\n",
            "9.0           1696      1.714475\n",
            "14.0          1241      2.343070\n",
            "2.0            829      3.507539\n",
            "12.0           817      3.559058\n",
            "1.0            777      3.742278\n",
            "5.0            587      4.953578\n",
            "6.0            551      5.277223\n",
            "3.0            397      7.324307\n",
            "13.0           234     12.426282\n",
            "7.0             65     44.734615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, val_generator, test_generator=get_image_generators(labels=labels, train_path=train_path, test_path=test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obmSjifp0mU2",
        "outputId": "7add10a5-4baf-4eeb-e696-ea435e8d3b43"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 37220 validated image filenames.\n",
            "Found 9304 validated image filenames.\n",
            "Found 25596 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrqJbsqOTTFO",
        "outputId": "84af71b8-41b7-4699-ba63-2403035f044d"
      },
      "source": [
        "model=create_model(trainable=False)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5017650   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 50)               200       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 50)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1530      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 30)               120       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 30)                0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15)                465       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 15)               60        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,584,825\n",
            "Trainable params: 5,019,835\n",
            "Non-trainable params: 23,564,990\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zv1BdGUTTHS"
      },
      "source": [
        "my_callbacks = [ tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"auto\", baseline=None, min_delta=0.01),]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_generator, val_generator, test_generator, model, my_callbacks ):\n",
        "  res=pd.DataFrame() # Create df to store results \n",
        "  count=1\n",
        "  for lr in [0.0001]: # a range of learning rates were tested , including [0.001, 0.0001, 0.00001] with training done in seperate notebooks to speed up tuning \n",
        "    for optimizer in [tf.keras.optimizers.Adam(learning_rate=lr), tf.keras.optimizers.SGD(learning_rate=lr)]:\n",
        "      for batch in [32, 256, 512]:\n",
        "        print(lr, optimizer, batch)\n",
        "\n",
        "        key=str(lr)+\"_\"+str(count)+\"_\"+str(batch)\n",
        "\n",
        "        # Estimate step size for generator \n",
        "        STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "\n",
        "        # Compile Model with metrics = Accuracy & AUC\n",
        "        model.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[tf.keras.metrics.binary_accuracy, tf.keras.metrics.AUC(multi_label=True)])\n",
        "\n",
        "        # Fit Model \n",
        "        history = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_generator, class_weight=class_weights_dict, #callbacks=my_callbacks,\n",
        "                            epochs=50)\n",
        "        # Predict \n",
        "        preds=model.predict(test_generator)\n",
        "\n",
        "        # Store ROC_AUC scores for each class \n",
        "        for i in range(15):\n",
        "          res.loc[i, 'Disease'+str(key)]= test.columns[i+2]\n",
        "          res.loc[i, 'AUC'+str(key)] = roc_auc_score(test.iloc[:,i+2], preds[:,i], average='samples')\n",
        "        # Store in Colab folder \n",
        "        with open('/ResNetDict_0_0001', 'ab') as file_pi:\n",
        "            pickle.dump(history.history, file_pi)\n",
        "\n",
        "        count=count+1\n",
        " "
      ],
      "metadata": {
        "id": "0mw83smY5JoP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoGlwUxdTs7D",
        "outputId": "b71727e8-cc80-4e42-cf2d-6ababf537757"
      },
      "source": [
        "train(train_generator, val_generator, test_generator, model, my_callbacks )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001 <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe53e085a90> 32\n",
            "Found 37220 validated image filenames.\n",
            "Found 9304 validated image filenames.\n",
            "Found 25596 validated image filenames.\n",
            "Epoch 1/50\n",
            "1163/1163 [==============================] - 118s 84ms/step - loss: 1.1398 - binary_accuracy: 0.5541 - auc: 0.5172 - val_loss: 0.7907 - val_binary_accuracy: 0.5987 - val_auc: 0.5483\n",
            "Epoch 2/50\n",
            "1163/1163 [==============================] - 91s 78ms/step - loss: 0.9844 - binary_accuracy: 0.6433 - auc: 0.5433 - val_loss: 0.7624 - val_binary_accuracy: 0.6252 - val_auc: 0.5403\n",
            "Epoch 3/50\n",
            "1163/1163 [==============================] - 90s 78ms/step - loss: 0.8892 - binary_accuracy: 0.6816 - auc: 0.5508 - val_loss: 0.6968 - val_binary_accuracy: 0.6736 - val_auc: 0.5486\n",
            "Epoch 4/50\n",
            "1163/1163 [==============================] - 90s 77ms/step - loss: 0.8110 - binary_accuracy: 0.7091 - auc: 0.5583 - val_loss: 0.6429 - val_binary_accuracy: 0.7104 - val_auc: 0.5429\n",
            "Epoch 5/50\n",
            "1163/1163 [==============================] - 89s 77ms/step - loss: 0.7419 - binary_accuracy: 0.7280 - auc: 0.5666 - val_loss: 0.6692 - val_binary_accuracy: 0.6746 - val_auc: 0.5458\n",
            "Epoch 6/50\n",
            "1163/1163 [==============================] - 90s 78ms/step - loss: 0.6884 - binary_accuracy: 0.7447 - auc: 0.5787 - val_loss: 0.6225 - val_binary_accuracy: 0.7080 - val_auc: 0.5556\n",
            "Epoch 7/50\n",
            "1163/1163 [==============================] - 90s 77ms/step - loss: 0.6313 - binary_accuracy: 0.7596 - auc: 0.5858 - val_loss: 0.5032 - val_binary_accuracy: 0.8049 - val_auc: 0.5715\n",
            "Epoch 8/50\n",
            "1163/1163 [==============================] - 89s 77ms/step - loss: 0.5952 - binary_accuracy: 0.7753 - auc: 0.6039 - val_loss: 0.5439 - val_binary_accuracy: 0.7625 - val_auc: 0.5658\n",
            "Epoch 9/50\n",
            "1163/1163 [==============================] - 89s 76ms/step - loss: 0.5521 - binary_accuracy: 0.7908 - auc: 0.6329 - val_loss: 0.4407 - val_binary_accuracy: 0.8542 - val_auc: 0.5917\n",
            "Epoch 10/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.5211 - binary_accuracy: 0.8076 - auc: 0.6560 - val_loss: 0.4291 - val_binary_accuracy: 0.8611 - val_auc: 0.5906\n",
            "Epoch 11/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.4935 - binary_accuracy: 0.8230 - auc: 0.6797 - val_loss: 0.4386 - val_binary_accuracy: 0.8512 - val_auc: 0.5952\n",
            "Epoch 12/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.4625 - binary_accuracy: 0.8380 - auc: 0.7071 - val_loss: 0.4247 - val_binary_accuracy: 0.8556 - val_auc: 0.5978\n",
            "Epoch 13/50\n",
            "1163/1163 [==============================] - 89s 77ms/step - loss: 0.4375 - binary_accuracy: 0.8525 - auc: 0.7282 - val_loss: 0.4215 - val_binary_accuracy: 0.8607 - val_auc: 0.6051\n",
            "Epoch 14/50\n",
            "1163/1163 [==============================] - 89s 77ms/step - loss: 0.4155 - binary_accuracy: 0.8639 - auc: 0.7519 - val_loss: 0.3840 - val_binary_accuracy: 0.8843 - val_auc: 0.6146\n",
            "Epoch 15/50\n",
            "1163/1163 [==============================] - 89s 76ms/step - loss: 0.4025 - binary_accuracy: 0.8727 - auc: 0.7730 - val_loss: 0.3522 - val_binary_accuracy: 0.9077 - val_auc: 0.6054\n",
            "Epoch 16/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.3799 - binary_accuracy: 0.8825 - auc: 0.7905 - val_loss: 0.3406 - val_binary_accuracy: 0.9102 - val_auc: 0.6145\n",
            "Epoch 17/50\n",
            "1163/1163 [==============================] - 89s 76ms/step - loss: 0.3579 - binary_accuracy: 0.8895 - auc: 0.8018 - val_loss: 0.3295 - val_binary_accuracy: 0.9127 - val_auc: 0.6191\n",
            "Epoch 18/50\n",
            "1163/1163 [==============================] - 89s 76ms/step - loss: 0.3421 - binary_accuracy: 0.8962 - auc: 0.8181 - val_loss: 0.3338 - val_binary_accuracy: 0.9104 - val_auc: 0.6203\n",
            "Epoch 19/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.3343 - binary_accuracy: 0.9005 - auc: 0.8302 - val_loss: 0.3270 - val_binary_accuracy: 0.9096 - val_auc: 0.6179\n",
            "Epoch 20/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.3157 - binary_accuracy: 0.9049 - auc: 0.8387 - val_loss: 0.3110 - val_binary_accuracy: 0.9146 - val_auc: 0.6289\n",
            "Epoch 21/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.3028 - binary_accuracy: 0.9081 - auc: 0.8474 - val_loss: 0.3099 - val_binary_accuracy: 0.9150 - val_auc: 0.6291\n",
            "Epoch 22/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.2902 - binary_accuracy: 0.9112 - auc: 0.8535 - val_loss: 0.2951 - val_binary_accuracy: 0.9173 - val_auc: 0.6372\n",
            "Epoch 23/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.2870 - binary_accuracy: 0.9138 - auc: 0.8605 - val_loss: 0.2936 - val_binary_accuracy: 0.9160 - val_auc: 0.6235\n",
            "Epoch 24/50\n",
            "1163/1163 [==============================] - 85s 73ms/step - loss: 0.2719 - binary_accuracy: 0.9159 - auc: 0.8696 - val_loss: 0.2913 - val_binary_accuracy: 0.9160 - val_auc: 0.6331\n",
            "Epoch 25/50\n",
            "1163/1163 [==============================] - 84s 72ms/step - loss: 0.2635 - binary_accuracy: 0.9191 - auc: 0.8745 - val_loss: 0.2893 - val_binary_accuracy: 0.9169 - val_auc: 0.6372\n",
            "Epoch 26/50\n",
            "1163/1163 [==============================] - 85s 73ms/step - loss: 0.2579 - binary_accuracy: 0.9204 - auc: 0.8789 - val_loss: 0.2901 - val_binary_accuracy: 0.9121 - val_auc: 0.6281\n",
            "Epoch 27/50\n",
            "1163/1163 [==============================] - 84s 72ms/step - loss: 0.2515 - binary_accuracy: 0.9220 - auc: 0.8838 - val_loss: 0.2826 - val_binary_accuracy: 0.9159 - val_auc: 0.6317\n",
            "Epoch 28/50\n",
            "1163/1163 [==============================] - 84s 72ms/step - loss: 0.2401 - binary_accuracy: 0.9249 - auc: 0.8912 - val_loss: 0.2763 - val_binary_accuracy: 0.9170 - val_auc: 0.6333\n",
            "Epoch 29/50\n",
            "1163/1163 [==============================] - 85s 73ms/step - loss: 0.2333 - binary_accuracy: 0.9254 - auc: 0.8920 - val_loss: 0.2715 - val_binary_accuracy: 0.9185 - val_auc: 0.6345\n",
            "Epoch 30/50\n",
            "1163/1163 [==============================] - 84s 73ms/step - loss: 0.2263 - binary_accuracy: 0.9268 - auc: 0.8993 - val_loss: 0.2729 - val_binary_accuracy: 0.9169 - val_auc: 0.6349\n",
            "Epoch 31/50\n",
            "1163/1163 [==============================] - 85s 73ms/step - loss: 0.2241 - binary_accuracy: 0.9279 - auc: 0.9012 - val_loss: 0.2762 - val_binary_accuracy: 0.9127 - val_auc: 0.6296\n",
            "Epoch 32/50\n",
            "1163/1163 [==============================] - 84s 72ms/step - loss: 0.2130 - binary_accuracy: 0.9300 - auc: 0.9024 - val_loss: 0.2727 - val_binary_accuracy: 0.9123 - val_auc: 0.6339\n",
            "Epoch 33/50\n",
            "1163/1163 [==============================] - 85s 73ms/step - loss: 0.2152 - binary_accuracy: 0.9307 - auc: 0.9071 - val_loss: 0.2705 - val_binary_accuracy: 0.9138 - val_auc: 0.6317\n",
            "Epoch 34/50\n",
            "1163/1163 [==============================] - 84s 73ms/step - loss: 0.2148 - binary_accuracy: 0.9304 - auc: 0.9066 - val_loss: 0.2726 - val_binary_accuracy: 0.9118 - val_auc: 0.6265\n",
            "Epoch 35/50\n",
            "1163/1163 [==============================] - 84s 72ms/step - loss: 0.2027 - binary_accuracy: 0.9325 - auc: 0.9124 - val_loss: 0.2625 - val_binary_accuracy: 0.9158 - val_auc: 0.6339\n",
            "Epoch 36/50\n",
            "1163/1163 [==============================] - 89s 76ms/step - loss: 0.2005 - binary_accuracy: 0.9344 - auc: 0.9177 - val_loss: 0.2661 - val_binary_accuracy: 0.9139 - val_auc: 0.6439\n",
            "Epoch 37/50\n",
            "1163/1163 [==============================] - 91s 78ms/step - loss: 0.1943 - binary_accuracy: 0.9351 - auc: 0.9153 - val_loss: 0.2634 - val_binary_accuracy: 0.9151 - val_auc: 0.6340\n",
            "Epoch 38/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.1929 - binary_accuracy: 0.9354 - auc: 0.9160 - val_loss: 0.2673 - val_binary_accuracy: 0.9108 - val_auc: 0.6341\n",
            "Epoch 39/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.1846 - binary_accuracy: 0.9382 - auc: 0.9245 - val_loss: 0.2613 - val_binary_accuracy: 0.9127 - val_auc: 0.6317\n",
            "Epoch 40/50\n",
            "1163/1163 [==============================] - 88s 76ms/step - loss: 0.1872 - binary_accuracy: 0.9378 - auc: 0.9202 - val_loss: 0.2629 - val_binary_accuracy: 0.9145 - val_auc: 0.6375\n",
            "Epoch 41/50\n",
            "1163/1163 [==============================] - 87s 74ms/step - loss: 0.1820 - binary_accuracy: 0.9388 - auc: 0.9218 - val_loss: 0.2600 - val_binary_accuracy: 0.9153 - val_auc: 0.6384\n",
            "Epoch 42/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1788 - binary_accuracy: 0.9390 - auc: 0.9247 - val_loss: 0.2599 - val_binary_accuracy: 0.9121 - val_auc: 0.6324\n",
            "Epoch 43/50\n",
            "1163/1163 [==============================] - 87s 75ms/step - loss: 0.1773 - binary_accuracy: 0.9397 - auc: 0.9269 - val_loss: 0.2635 - val_binary_accuracy: 0.9093 - val_auc: 0.6374\n",
            "Epoch 44/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1755 - binary_accuracy: 0.9405 - auc: 0.9283 - val_loss: 0.2601 - val_binary_accuracy: 0.9110 - val_auc: 0.6361\n",
            "Epoch 45/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1733 - binary_accuracy: 0.9418 - auc: 0.9296 - val_loss: 0.2582 - val_binary_accuracy: 0.9149 - val_auc: 0.6312\n",
            "Epoch 46/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1720 - binary_accuracy: 0.9419 - auc: 0.9310 - val_loss: 0.2606 - val_binary_accuracy: 0.9138 - val_auc: 0.6390\n",
            "Epoch 47/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1686 - binary_accuracy: 0.9427 - auc: 0.9359 - val_loss: 0.2593 - val_binary_accuracy: 0.9140 - val_auc: 0.6323\n",
            "Epoch 48/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1662 - binary_accuracy: 0.9434 - auc: 0.9355 - val_loss: 0.2576 - val_binary_accuracy: 0.9132 - val_auc: 0.6379\n",
            "Epoch 49/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1649 - binary_accuracy: 0.9435 - auc: 0.9367 - val_loss: 0.2537 - val_binary_accuracy: 0.9134 - val_auc: 0.6347\n",
            "Epoch 50/50\n",
            "1163/1163 [==============================] - 86s 74ms/step - loss: 0.1624 - binary_accuracy: 0.9449 - auc: 0.9388 - val_loss: 0.2563 - val_binary_accuracy: 0.9135 - val_auc: 0.6405\n",
            "0.0001 <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe53e085a90> 256\n",
            "Found 37220 validated image filenames.\n",
            "Found 9304 validated image filenames.\n",
            "Found 25596 validated image filenames.\n",
            "Epoch 1/50\n",
            "145/145 [==============================] - 90s 581ms/step - loss: 1.1433 - binary_accuracy: 0.5390 - auc_1: 0.5307 - val_loss: 1.1798 - val_binary_accuracy: 0.4242 - val_auc_1: 0.5456\n",
            "Epoch 2/50\n",
            "145/145 [==============================] - 81s 558ms/step - loss: 1.0116 - binary_accuracy: 0.6159 - auc_1: 0.5496 - val_loss: 0.8005 - val_binary_accuracy: 0.5942 - val_auc_1: 0.5533\n",
            "Epoch 3/50\n",
            "145/145 [==============================] - 80s 554ms/step - loss: 0.9710 - binary_accuracy: 0.6459 - auc_1: 0.5571 - val_loss: 0.6607 - val_binary_accuracy: 0.6988 - val_auc_1: 0.5626\n",
            "Epoch 4/50\n",
            "145/145 [==============================] - 79s 545ms/step - loss: 0.8924 - binary_accuracy: 0.6608 - auc_1: 0.5561 - val_loss: 0.6221 - val_binary_accuracy: 0.7333 - val_auc_1: 0.5684\n",
            "Epoch 5/50\n",
            "145/145 [==============================] - 79s 544ms/step - loss: 0.8524 - binary_accuracy: 0.6675 - auc_1: 0.5584 - val_loss: 0.6230 - val_binary_accuracy: 0.7316 - val_auc_1: 0.5569\n",
            "Epoch 6/50\n",
            "145/145 [==============================] - 79s 544ms/step - loss: 0.8143 - binary_accuracy: 0.6699 - auc_1: 0.5562 - val_loss: 0.6457 - val_binary_accuracy: 0.7064 - val_auc_1: 0.5465\n",
            "Epoch 7/50\n",
            "145/145 [==============================] - 80s 553ms/step - loss: 0.7781 - binary_accuracy: 0.6674 - auc_1: 0.5603 - val_loss: 0.6878 - val_binary_accuracy: 0.6643 - val_auc_1: 0.5416\n",
            "Epoch 8/50\n",
            "145/145 [==============================] - 82s 561ms/step - loss: 0.7583 - binary_accuracy: 0.6664 - auc_1: 0.5567 - val_loss: 0.6494 - val_binary_accuracy: 0.6965 - val_auc_1: 0.5403\n",
            "Epoch 9/50\n",
            "145/145 [==============================] - 83s 572ms/step - loss: 0.7315 - binary_accuracy: 0.6639 - auc_1: 0.5605 - val_loss: 0.6345 - val_binary_accuracy: 0.7059 - val_auc_1: 0.5482\n",
            "Epoch 10/50\n",
            "145/145 [==============================] - 82s 561ms/step - loss: 0.7086 - binary_accuracy: 0.6624 - auc_1: 0.5668 - val_loss: 0.6919 - val_binary_accuracy: 0.6516 - val_auc_1: 0.5312\n",
            "Epoch 11/50\n",
            "145/145 [==============================] - 81s 556ms/step - loss: 0.6937 - binary_accuracy: 0.6600 - auc_1: 0.5700 - val_loss: 0.6909 - val_binary_accuracy: 0.6371 - val_auc_1: 0.5361\n",
            "Epoch 12/50\n",
            "145/145 [==============================] - 80s 553ms/step - loss: 0.6696 - binary_accuracy: 0.6614 - auc_1: 0.5752 - val_loss: 0.6492 - val_binary_accuracy: 0.6773 - val_auc_1: 0.5432\n",
            "Epoch 13/50\n",
            "145/145 [==============================] - 80s 554ms/step - loss: 0.6604 - binary_accuracy: 0.6608 - auc_1: 0.5866 - val_loss: 0.6669 - val_binary_accuracy: 0.6624 - val_auc_1: 0.5378\n",
            "Epoch 14/50\n",
            "145/145 [==============================] - 80s 551ms/step - loss: 0.6464 - binary_accuracy: 0.6610 - auc_1: 0.5920 - val_loss: 0.6595 - val_binary_accuracy: 0.6594 - val_auc_1: 0.5368\n",
            "Epoch 15/50\n",
            "145/145 [==============================] - 82s 563ms/step - loss: 0.6304 - binary_accuracy: 0.6629 - auc_1: 0.6040 - val_loss: 0.6567 - val_binary_accuracy: 0.6625 - val_auc_1: 0.5402\n",
            "Epoch 16/50\n",
            "145/145 [==============================] - 83s 572ms/step - loss: 0.6209 - binary_accuracy: 0.6653 - auc_1: 0.6114 - val_loss: 0.6842 - val_binary_accuracy: 0.6293 - val_auc_1: 0.5457\n",
            "Epoch 17/50\n",
            "145/145 [==============================] - 83s 571ms/step - loss: 0.6128 - binary_accuracy: 0.6669 - auc_1: 0.6173 - val_loss: 0.6162 - val_binary_accuracy: 0.6953 - val_auc_1: 0.5456\n",
            "Epoch 18/50\n",
            "145/145 [==============================] - 80s 552ms/step - loss: 0.6026 - binary_accuracy: 0.6693 - auc_1: 0.6336 - val_loss: 0.5822 - val_binary_accuracy: 0.7339 - val_auc_1: 0.5572\n",
            "Epoch 19/50\n",
            "145/145 [==============================] - 81s 557ms/step - loss: 0.5911 - binary_accuracy: 0.6712 - auc_1: 0.6363 - val_loss: 0.6091 - val_binary_accuracy: 0.7020 - val_auc_1: 0.5559\n",
            "Epoch 20/50\n",
            "145/145 [==============================] - 80s 551ms/step - loss: 0.5819 - binary_accuracy: 0.6725 - auc_1: 0.6512 - val_loss: 0.6561 - val_binary_accuracy: 0.6515 - val_auc_1: 0.5521\n",
            "Epoch 21/50\n",
            "145/145 [==============================] - 80s 552ms/step - loss: 0.5710 - binary_accuracy: 0.6776 - auc_1: 0.6517 - val_loss: 0.6043 - val_binary_accuracy: 0.7076 - val_auc_1: 0.5520\n",
            "Epoch 22/50\n",
            "145/145 [==============================] - 80s 551ms/step - loss: 0.5613 - binary_accuracy: 0.6800 - auc_1: 0.6716 - val_loss: 0.6587 - val_binary_accuracy: 0.6505 - val_auc_1: 0.5482\n",
            "Epoch 23/50\n",
            "145/145 [==============================] - 81s 554ms/step - loss: 0.5491 - binary_accuracy: 0.6827 - auc_1: 0.6705 - val_loss: 0.5843 - val_binary_accuracy: 0.7226 - val_auc_1: 0.5524\n",
            "Epoch 24/50\n",
            "145/145 [==============================] - 81s 555ms/step - loss: 0.5446 - binary_accuracy: 0.6864 - auc_1: 0.6814 - val_loss: 0.6267 - val_binary_accuracy: 0.6819 - val_auc_1: 0.5530\n",
            "Epoch 25/50\n",
            "145/145 [==============================] - 80s 552ms/step - loss: 0.5354 - binary_accuracy: 0.6887 - auc_1: 0.6853 - val_loss: 0.7392 - val_binary_accuracy: 0.5831 - val_auc_1: 0.5404\n",
            "Epoch 26/50\n",
            "145/145 [==============================] - 82s 568ms/step - loss: 0.5350 - binary_accuracy: 0.6934 - auc_1: 0.6949 - val_loss: 0.5741 - val_binary_accuracy: 0.7323 - val_auc_1: 0.5602\n",
            "Epoch 27/50\n",
            "145/145 [==============================] - 84s 576ms/step - loss: 0.5252 - binary_accuracy: 0.6966 - auc_1: 0.7035 - val_loss: 0.6088 - val_binary_accuracy: 0.6959 - val_auc_1: 0.5568\n",
            "Epoch 28/50\n",
            "145/145 [==============================] - 84s 579ms/step - loss: 0.5190 - binary_accuracy: 0.7022 - auc_1: 0.7119 - val_loss: 0.5585 - val_binary_accuracy: 0.7465 - val_auc_1: 0.5592\n",
            "Epoch 29/50\n",
            "145/145 [==============================] - 84s 579ms/step - loss: 0.5120 - binary_accuracy: 0.7039 - auc_1: 0.7167 - val_loss: 0.5498 - val_binary_accuracy: 0.7544 - val_auc_1: 0.5650\n",
            "Epoch 30/50\n",
            "145/145 [==============================] - 83s 570ms/step - loss: 0.4992 - binary_accuracy: 0.7079 - auc_1: 0.7263 - val_loss: 0.5928 - val_binary_accuracy: 0.7142 - val_auc_1: 0.5562\n",
            "Epoch 31/50\n",
            "145/145 [==============================] - 83s 568ms/step - loss: 0.5000 - binary_accuracy: 0.7111 - auc_1: 0.7332 - val_loss: 0.5843 - val_binary_accuracy: 0.7182 - val_auc_1: 0.5634\n",
            "Epoch 32/50\n",
            "145/145 [==============================] - 82s 567ms/step - loss: 0.4988 - binary_accuracy: 0.7168 - auc_1: 0.7373 - val_loss: 0.5693 - val_binary_accuracy: 0.7356 - val_auc_1: 0.5572\n",
            "Epoch 33/50\n",
            "145/145 [==============================] - 83s 575ms/step - loss: 0.4866 - binary_accuracy: 0.7176 - auc_1: 0.7447 - val_loss: 0.5688 - val_binary_accuracy: 0.7322 - val_auc_1: 0.5641\n",
            "Epoch 34/50\n",
            "145/145 [==============================] - 82s 563ms/step - loss: 0.4777 - binary_accuracy: 0.7223 - auc_1: 0.7495 - val_loss: 0.5728 - val_binary_accuracy: 0.7299 - val_auc_1: 0.5698\n",
            "Epoch 35/50\n",
            "145/145 [==============================] - 83s 568ms/step - loss: 0.4721 - binary_accuracy: 0.7245 - auc_1: 0.7563 - val_loss: 0.6170 - val_binary_accuracy: 0.6859 - val_auc_1: 0.5578\n",
            "Epoch 36/50\n",
            "145/145 [==============================] - 83s 570ms/step - loss: 0.4662 - binary_accuracy: 0.7292 - auc_1: 0.7673 - val_loss: 0.5656 - val_binary_accuracy: 0.7354 - val_auc_1: 0.5729\n",
            "Epoch 37/50\n",
            "145/145 [==============================] - 84s 581ms/step - loss: 0.4583 - binary_accuracy: 0.7310 - auc_1: 0.7666 - val_loss: 0.5692 - val_binary_accuracy: 0.7311 - val_auc_1: 0.5702\n",
            "Epoch 38/50\n",
            "145/145 [==============================] - 85s 585ms/step - loss: 0.4537 - binary_accuracy: 0.7352 - auc_1: 0.7773 - val_loss: 0.5814 - val_binary_accuracy: 0.7178 - val_auc_1: 0.5711\n",
            "Epoch 39/50\n",
            "145/145 [==============================] - 84s 576ms/step - loss: 0.4486 - binary_accuracy: 0.7411 - auc_1: 0.7825 - val_loss: 0.5191 - val_binary_accuracy: 0.7800 - val_auc_1: 0.5723\n",
            "Epoch 40/50\n",
            "145/145 [==============================] - 84s 579ms/step - loss: 0.4435 - binary_accuracy: 0.7446 - auc_1: 0.7858 - val_loss: 0.5621 - val_binary_accuracy: 0.7332 - val_auc_1: 0.5716\n",
            "Epoch 41/50\n",
            "145/145 [==============================] - 82s 564ms/step - loss: 0.4358 - binary_accuracy: 0.7472 - auc_1: 0.7937 - val_loss: 0.5748 - val_binary_accuracy: 0.7264 - val_auc_1: 0.5674\n",
            "Epoch 42/50\n",
            "145/145 [==============================] - 81s 560ms/step - loss: 0.4262 - binary_accuracy: 0.7500 - auc_1: 0.7964 - val_loss: 0.5424 - val_binary_accuracy: 0.7547 - val_auc_1: 0.5783\n",
            "Epoch 43/50\n",
            "145/145 [==============================] - 82s 562ms/step - loss: 0.4251 - binary_accuracy: 0.7549 - auc_1: 0.8033 - val_loss: 0.5681 - val_binary_accuracy: 0.7327 - val_auc_1: 0.5689\n",
            "Epoch 44/50\n",
            "145/145 [==============================] - 82s 561ms/step - loss: 0.4164 - binary_accuracy: 0.7572 - auc_1: 0.8088 - val_loss: 0.5552 - val_binary_accuracy: 0.7411 - val_auc_1: 0.5758\n",
            "Epoch 45/50\n",
            "145/145 [==============================] - 82s 562ms/step - loss: 0.4166 - binary_accuracy: 0.7627 - auc_1: 0.8176 - val_loss: 0.5610 - val_binary_accuracy: 0.7339 - val_auc_1: 0.5737\n",
            "Epoch 46/50\n",
            "145/145 [==============================] - 82s 562ms/step - loss: 0.4075 - binary_accuracy: 0.7639 - auc_1: 0.8188 - val_loss: 0.5267 - val_binary_accuracy: 0.7687 - val_auc_1: 0.5742\n",
            "Epoch 47/50\n",
            "145/145 [==============================] - 81s 560ms/step - loss: 0.4039 - binary_accuracy: 0.7681 - auc_1: 0.8215 - val_loss: 0.5258 - val_binary_accuracy: 0.7687 - val_auc_1: 0.5763\n",
            "Epoch 48/50\n",
            "145/145 [==============================] - 82s 564ms/step - loss: 0.3955 - binary_accuracy: 0.7699 - auc_1: 0.8247 - val_loss: 0.5009 - val_binary_accuracy: 0.7946 - val_auc_1: 0.5842\n",
            "Epoch 49/50\n",
            "145/145 [==============================] - 82s 563ms/step - loss: 0.3926 - binary_accuracy: 0.7727 - auc_1: 0.8266 - val_loss: 0.5184 - val_binary_accuracy: 0.7736 - val_auc_1: 0.5788\n",
            "Epoch 50/50\n",
            "145/145 [==============================] - 82s 562ms/step - loss: 0.3881 - binary_accuracy: 0.7766 - auc_1: 0.8348 - val_loss: 0.5130 - val_binary_accuracy: 0.7754 - val_auc_1: 0.5762\n",
            "0.0001 <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fe53e085a90> 512\n",
            "Found 37220 validated image filenames.\n",
            "Found 9304 validated image filenames.\n",
            "Found 25596 validated image filenames.\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - 95s 1s/step - loss: 1.1561 - binary_accuracy: 0.5345 - auc_2: 0.5128 - val_loss: 1.4790 - val_binary_accuracy: 0.3142 - val_auc_2: 0.5194\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - 97s 1s/step - loss: 1.0579 - binary_accuracy: 0.5977 - auc_2: 0.5334 - val_loss: 0.9575 - val_binary_accuracy: 0.4877 - val_auc_2: 0.5233\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - 96s 1s/step - loss: 0.9776 - binary_accuracy: 0.6258 - auc_2: 0.5318 - val_loss: 0.7380 - val_binary_accuracy: 0.6248 - val_auc_2: 0.5405\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - 96s 1s/step - loss: 0.9309 - binary_accuracy: 0.6353 - auc_2: 0.5278 - val_loss: 0.6497 - val_binary_accuracy: 0.7102 - val_auc_2: 0.5419\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - 96s 1s/step - loss: 0.8929 - binary_accuracy: 0.6410 - auc_2: 0.5293 - val_loss: 0.5704 - val_binary_accuracy: 0.7845 - val_auc_2: 0.5550\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - 96s 1s/step - loss: 0.8525 - binary_accuracy: 0.6400 - auc_2: 0.5280 - val_loss: 0.5871 - val_binary_accuracy: 0.7603 - val_auc_2: 0.5459\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - 96s 1s/step - loss: 0.8281 - binary_accuracy: 0.6379 - auc_2: 0.5242 - val_loss: 0.6015 - val_binary_accuracy: 0.7402 - val_auc_2: 0.5451\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - 95s 1s/step - loss: 0.8012 - binary_accuracy: 0.6336 - auc_2: 0.5297 - val_loss: 0.6206 - val_binary_accuracy: 0.7117 - val_auc_2: 0.5440\n",
            "Epoch 9/50\n",
            "55/72 [=====================>........] - ETA: 17s - loss: 0.7660 - binary_accuracy: 0.6304 - auc_2: 0.5328"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6vnyfwwNw9v"
      },
      "source": [
        "# Copy results from Colab to Gdrive \n",
        "%cp -av '/ResNetDict_0_0001' 'gdrive/MyDrive/files' \n",
        "res=res.to_csv('res_ResNet_0_0001.csv')\n",
        "%cp -av 'res_ResNet_0_0001.csv' 'gdrive/MyDrive/files' \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z_uXjYlQ52ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhpAFOwjTtIK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urfn76diTtNN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkr_3sr6TtT6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}